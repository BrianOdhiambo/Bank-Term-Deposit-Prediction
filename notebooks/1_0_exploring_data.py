# -*- coding: utf-8 -*-
"""1.0-exploring-data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HsTmC0cb9aHItRgTjz7Fr-B_6AmNq8Pp

# Bank Institution Term Deposit Predictive Model

You successfully finished up to your rigorous job interview process with Bank of Portugal as a machine learning researcher. The investment and portfolio department would want to be able to identify their customers who potentially would subscribe to their term deposits. As there has been heightened interest of marketing managers to carefully tune their directed campaigns to the rigorous selection of contacts, the goal of your employer is to find a model that can predict which future clients who would subscribe to their term deposit. Having such an effective predictive model can help increase their campaign efficiency as they would be able to identify customers who would subscribe to their term deposit and thereby direct their marketing efforts to them. This would help them better manage their resources (e.g human effort, phone calls, time)
The Bank of Portugal, therefore, collected a huge amount of data that includes customers profiles of those who have to subscribe to term deposits and the ones who did not subscribe to a term deposit. As their newly employed machine learning researcher, they want you to come up with a robust predictive model that would help them identify customers who would or would not subscribe to their term deposit in the future.
Your main goal as a machine learning researcher is to carry out data exploration, data cleaning, feature extraction, and developing robust machine learning algorithms that would aid them in the department.

## Features
`Bank client data`
| `age`         | client's age (numeric)                                                |<br>
| `job`         | type of job (categorical)                                             |<br>
| `marital`     | marital status (categorical                                           |<br>
| `education`   | education level (categorical)                                         |<br>
| `default`     | if client has credit in default (categorical)                         |<br>
| `housing`     | if client has housing loan (categorical)                              |<br>
| `loan`        | if client has personal loan (categorical)                             |<br>

`Related with last contact of the current campaign`<br>
| `contact`     | contact communication type (categorical)                              |<br>
| `month`       | last contact month of the year (categorical)                          |<br>
| `day_of_week` | last contact day of the week (categorical)                            |<br>
| `duration`    | last contact duration, in seconds (numeric)                           |<br> 

`Other attributes`<br>
| `campaign`    | number of contacts performed during this campaign and for this client |<br> 
| `pdays`       | number of days that passed by after the client was last contacted from a previous campaign |<br>
| `previous`    | number of contacts performed before this campaign and for this client (numeric) |<br>
| `poutcome`    | outcome of the previous marketing campaign (categorical) |<br>

`Social and economic context attributes`<br>
| `emp.var.rate`   | employment variation rate - quarterly indicator (numeric) |<br>
| `cons.price.idx` | consumer price index - monthly indicator (numeric)        |<br>
| `cons.conf.idx`  | consumer confidence index - monthly indicator (numeric)   |<br>
| `euribor3m`      | euribor 3 month rate - daily indicator (numeric)          |<br>
| `nr.employed`    | number of employees - quarterly indicator (numeric)       |<br>

# Imports
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from pandas import Series,DataFrame
import numpy as np
from pandas import datetime

# data visualization
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('whitegrid')
import plotly.offline as py
from plotly.offline import init_notebook_mode, iplot
import plotly.graph_objs as go
init_notebook_mode(connected=True)
from bubbly.bubbly import bubbleplot

# %matplotlib inline

# statistics
from statsmodels.distributions.empirical_distribution import ECDF
from scipy import stats

# preprocessing and encoders
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer

# classification
from sklearn.model_selection import train_test_split

import dataframe_image as dfi

# time series analysis
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# Class imbalance
from imblearn.combine import SMOTETomek
from imblearn.over_sampling import RandomOverSampler
from collections import Counter

from sklearn.neighbors import LocalOutlierFactor as lof
lof = lof()
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM

# for warning ignore
import warnings
warnings.filterwarnings("ignore")

import os

"""# Loading Data"""

# set the path of the raw data
raw_data_path = os.path.join(os.path.pardir, 'data', 'raw')
df_file_path = os.path.join(raw_data_path, 'bank-additional-full.csv')

# read the data with all default parameters
df = pd.read_csv(df_file_path, sep=';')

df.info()

"""# Exploratory Data Analysis"""

df.head()

df.describe()

# Categorical features
df.describe(include='all')

"""### Checking for missing values in the dataset"""

print("Number of missing value(s): ", df.isnull().sum().value_counts())

"""There is no missing values in the dataset."""

# columns : Age
age_count = df['age'].value_counts().head()
print("Age count")
print("----------")
age_count

# categorical column : Job
job_count = df['job'].value_counts()
print("Job count")
print("---------")
job_count

# categorical column : marital
marital_count = df["marital"].value_counts()
print("Marital count")
print("-------------")
marital_count

# categorical column : education
education_count = df["education"].value_counts()
print("Education count")
print("-------------")
education_count

# categorical column : housing
housing_count = df["housing"].value_counts()
print("Housing count")
print("-------------")
housing_count

# categorical column : housing
loan_count = df["loan"].value_counts()
print("Loan count")
print("-------------")
loan_count

y_count = df['y'].value_counts()
print("Y count")
print("----------")
y_count

"""# Univariate Analysis"""

sns.catplot(x = 'y', data =  df, kind = "count")

# checking the distribution of age

plt.style.use('fivethirtyeight')
plt.rcParams['figure.figsize'] = (15, 5)
sns.distplot(df['age'], color = 'cyan')
plt.title('Distribution of Age', fontsize = 20)
plt.show()

"""There is a positive skewness in the age distribution"""

sns.catplot(x = 'marital', data =  df, kind = "count")

sns.catplot(x = 'job', data =  df, kind = "count")
plt.xticks(rotation = 90)

plt.show()

sns.catplot(x = 'education', data =  df, kind = "count")
plt.xticks(rotation = 75)

plt.show()

"""## Bivariate Analysis"""

df.corr()

# making heat map

plt.rcParams['figure.figsize'] = (20, 15)
plt.style.use('ggplot')

sns.heatmap(df.corr(), annot = True, cmap = 'Wistia')
plt.title('Heatmap for the Dataset', fontsize = 20)
plt.show()

"""# Boxplot : Education vs Age vs Target"""

def boxplot(x, y, data=df, hue = 'y'):
    plot = sns.boxplot(x= x, y=y, hue=hue, data= data)
    plt.xticks( rotation=45, horizontalalignment='right' )
    plt.title("Boxplot of " + " " + x.upper() + " " + "and "+ " " + y.upper())
    return plot

boxplot("education", "age", data=df, hue="y")

"""# Marital vs Age vs Target"""

boxplot("marital", "age", data=df, hue= "y")

"""# Data Preprocessing

## Dropping Duration column.
This variable highly affects the output target (e.g., if duration=0 then y='no'). Yet the duration is known before a call is performed. Also after the end of the call, y is obviously known. For realistic prediction, duration should be dropped
"""

df = df.drop(['duration'], axis=1)

df

df['education'].replace({'basic.9y': 'basic','basic.4y': 'basic','basic.6y':'basic','unknown':'illiterate'},inplace=True)

df['education'].value_counts()

df['job'].replace({'self-employed': 'entrepreneur','unknown': 'unemployed'},inplace=True)

df['job'].value_counts()

df.shape

"""# Categorical Encoding"""

# y column
# Binary Encoding
df['subscription'] = np.where(df.y == 'yes', 1, 0)

# categorical columns
# OneHotEncoding
df = pd.get_dummies(df, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month',
                                'day_of_week', 'poutcome'])

df = df.drop(['y'], axis=1)

# reorder columns
columns = [column for column in df.columns if column != 'subscription']
columns = columns + ['subscription']
df = df[columns]

df.info()

# Scaling numeric columns

# Select numerical columns
num_cols = ['emp.var.rate',"pdays","age", 'cons.price.idx','cons.conf.idx', 'euribor3m', 'nr.employed']

scaler = StandardScaler()
df[num_cols] = scaler.fit_transform(df[num_cols])

df

# Create independent and Dependent features
columns = df.columns.tolist()
# Filter the columns to remove data we do not want
columns = [c for c in columns if c not in ["subscription"]]
# Store the variable we are predicting
target = "subscription"
# Define a random state
state = np.random.RandomState(42)
X = df[columns]
y = df[target]
X_outliers = state.uniform(low=0, high=1, size=(X.shape[0], X.shape[1]))
# print the shapes of X and Y
print(X.shape)
print(y.shape)

"""# Class Imbalance"""

LABELS = ["No", "Yes"]

# subscription column : Our target value

count_values = pd.value_counts(df['subscription'], sort = True)

count_values.plot(kind = 'bar', rot = 0)
plt.title("Subscription Class Distribution")
plt.xticks(range(2), LABELS)
plt.xlabel("Subscription")
plt.ylabel("Frequency")

"""There is class imbalance in the target variable, hence the need to improve it. We will use overfitting in this case"""

# Get the Yes and the No dataset

Yes = df[df["subscription"] == 1]
No = df[df["subscription"] == 0]

print(Yes.shape, No.shape)

"""# RandomOverSampler to Handle imbalanced Data"""

ros = RandomOverSampler(random_state=42)
X_res, y_res = ros.fit_resample(X, y)

X_res.shape

y_res.shape

print('Original dataset shape {}'.format(Counter(y)))
print('Resampled dataset shape {}'.format(Counter(y_res)))

"""# Principal Component Analysis"""

from sklearn.decomposition import PCA
pca = PCA(n_components = 10)
pca.fit(X_res)
X = pca.transform(X_res)

principal_df = pd.DataFrame(data = X
             , columns = ['PC_1', 'PC_2','PC_3', 'PC_4','PC_5','PC_6', 'PC_7',
                          'PC_8', 'PC_9','PC_10'])
principal_df

"""# Saved preprocessed data"""

processed_data_path = os.path.join(os.path.pardir, 'data','processed')
write_train_path = os.path.join(processed_data_path, 'train.csv')
write_test_path = os.path.join(processed_data_path, 'test.csv')

# train data
principal_df.to_csv(write_train_path, index=False)
#test data
y_res.to_csv(write_test_path, index=False)



